from setfit import SetFitModel, Trainer, TrainingArguments
from datasets import load_dataset
import torch

# Û±. Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ (ÛŒÚ© Ù…Ø¯Ù„ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ Ø³Ø¨Ú© Ùˆ Ø¹Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹)
model_id = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# Û². Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ (ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ ÙØ§ÛŒÙ„ Ø¯Ø± data/samples.json Ø§Ø³Øª)
# Ø¨Ø±Ø§ÛŒ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² ÛŒÚ© Ø¯ÛŒØªØ§Ø³Øª Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
dataset = load_dataset("json", data_files="data/samples.json")["train"]

# Û³. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ SetFit
model = SetFitModel.from_pretrained(model_id)

# Û´. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¢Ù…ÙˆØ²Ø´
args = TrainingArguments(
    batch_size=16,
    num_epochs=4,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
)

# Ûµ. ØªØ¹Ø±ÛŒÙ Trainer
trainer = Trainer(
    model=model,
    args=args,
    train_dataset=dataset,
)

# Û¶. Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´
print("ğŸš€ Starting training...")
trainer.train()

# Û·. Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ
model.save_pretrained("model/persian_intent_model")
print("âœ… Model saved successfully in 'model/' directory.")